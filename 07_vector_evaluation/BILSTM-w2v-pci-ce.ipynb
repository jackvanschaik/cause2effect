{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pci_vectors = pd.read_csv(\"pci_ce_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train.pkl\")\n",
    "test = pd.read_pickle(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['token']\n",
    "train_y = train['label']\n",
    "train_id = train['sen_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test['token']\n",
    "test_y = test['label']\n",
    "test_id = test['sen_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([item for sublist in train_x for item in sublist] + [item for sublist in test_x for item in sublist])\n",
    "tag = ['O', 'C', 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-305-758d4c807898>:1: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  vectors =pci_vectors.set_index('token').T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "vectors =pci_vectors.set_index('token').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors['arrows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_300 = np.array([0] * 300)\n",
    "zero_301 = np.concatenate((np.array([1]), zero_300))\n",
    "\n",
    "zero_100 = np.array([0] * 100)\n",
    "zero_101 = np.concatenate((np.array([1]), zero_100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "\n",
    "not_present = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vocab:\n",
    "    try:\n",
    "        vec = w2v_model[i]\n",
    "        vec1 = np.concatenate((np.array([0]), vec))\n",
    "        word2idx[i]= vec1\n",
    "        \n",
    "    except:\n",
    "        word2idx[i]= zero_301\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vocab:\n",
    "    try:\n",
    "        vec = vectors[i]\n",
    "        vec1 = np.concatenate((np.array([0]), vec))\n",
    "        word2idx[i]= np.concatenate((word2idx[i], vec1))\n",
    "    except:\n",
    "        word2idx[i]= np.concatenate((word2idx[i], zero_101))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -5.83496094e-02,  2.92968750e-01,  2.04101562e-01,\n",
       "       -3.47656250e-01, -4.22363281e-02, -1.76757812e-01,  2.08007812e-01,\n",
       "       -7.56835938e-03,  2.83203125e-01, -1.85546875e-01,  2.71484375e-01,\n",
       "       -1.69921875e-01,  4.83398438e-02, -1.74804688e-01, -9.52148438e-02,\n",
       "        2.62451172e-02, -1.73828125e-01, -1.44531250e-01, -3.66210938e-02,\n",
       "       -6.25000000e-02,  5.00488281e-02,  5.78613281e-02, -4.63867188e-02,\n",
       "       -2.05078125e-02,  1.33789062e-01, -2.55859375e-01, -1.36718750e-01,\n",
       "        1.15234375e-01,  9.17968750e-02, -3.51562500e-01, -2.31445312e-01,\n",
       "       -6.29882812e-02, -1.81640625e-01,  1.79687500e-01, -1.80664062e-01,\n",
       "       -2.50000000e-01,  7.47070312e-02,  3.00781250e-01,  1.64062500e-01,\n",
       "       -2.77343750e-01, -2.51953125e-01,  1.46484375e-01,  2.09960938e-01,\n",
       "       -1.88476562e-01, -4.49218750e-02, -2.08984375e-01, -1.01318359e-02,\n",
       "        2.99072266e-02, -1.48437500e-01,  2.73437500e-01,  4.05273438e-02,\n",
       "       -2.92968750e-01,  9.52148438e-02, -1.36718750e-01, -2.37304688e-01,\n",
       "       -2.27050781e-02, -1.70898438e-01,  3.83300781e-02,  1.54296875e-01,\n",
       "        3.17382812e-02,  1.04980469e-01, -1.96289062e-01,  2.25830078e-02,\n",
       "       -3.06640625e-01, -2.05078125e-01,  5.34667969e-02,  1.54296875e-01,\n",
       "        4.32128906e-02, -1.39648438e-01, -1.28906250e-01, -1.26953125e-01,\n",
       "       -6.88476562e-02,  1.35742188e-01, -2.01171875e-01, -2.67578125e-01,\n",
       "       -8.00781250e-02, -2.18750000e-01, -6.39648438e-02,  4.17968750e-01,\n",
       "       -1.68945312e-01,  1.52343750e-01,  2.96630859e-02, -1.79687500e-01,\n",
       "       -2.04101562e-01, -2.85156250e-01,  1.97265625e-01,  1.17187500e-01,\n",
       "       -2.38281250e-01,  2.77343750e-01, -1.44531250e-01, -2.96875000e-01,\n",
       "        2.91015625e-01, -9.66796875e-02,  2.79296875e-01, -3.33984375e-01,\n",
       "       -1.25976562e-01, -8.00781250e-02, -1.54296875e-01,  2.39257812e-01,\n",
       "        2.92968750e-03,  1.04492188e-01,  6.78710938e-02,  3.44238281e-02,\n",
       "       -3.16406250e-01, -5.85937500e-02,  2.34375000e-01, -1.04492188e-01,\n",
       "       -1.30859375e-01,  2.18750000e-01,  1.38671875e-01,  2.17773438e-01,\n",
       "       -1.19628906e-01,  2.94189453e-02, -2.51464844e-02,  2.70996094e-02,\n",
       "       -3.41796875e-01,  2.28515625e-01,  2.30468750e-01, -5.03906250e-01,\n",
       "       -8.64257812e-02,  2.08007812e-01,  3.82812500e-01, -1.85546875e-01,\n",
       "        2.02148438e-01, -1.76757812e-01,  5.00488281e-02,  7.76367188e-02,\n",
       "        3.44238281e-02, -1.05468750e-01,  3.66210938e-02, -1.45507812e-01,\n",
       "        1.15356445e-02, -7.91015625e-02, -2.12890625e-01,  1.09252930e-02,\n",
       "       -2.96875000e-01, -6.00585938e-02, -4.88281250e-02,  5.12695312e-02,\n",
       "        5.11718750e-01, -2.67578125e-01, -2.77343750e-01,  7.66601562e-02,\n",
       "       -9.71679688e-02, -1.77734375e-01, -2.51953125e-01, -7.22656250e-02,\n",
       "        4.78515625e-01, -1.14257812e-01, -3.63281250e-01,  2.36328125e-01,\n",
       "       -4.37500000e-01,  1.18652344e-01,  4.08203125e-01, -1.60156250e-01,\n",
       "       -2.00195312e-01,  2.71484375e-01, -7.66601562e-02,  1.33789062e-01,\n",
       "        7.50732422e-03, -9.86328125e-02, -1.15722656e-01, -1.01562500e-01,\n",
       "        1.05590820e-02, -3.56445312e-02, -1.94335938e-01,  1.17675781e-01,\n",
       "       -1.47460938e-01,  2.91748047e-02,  3.59375000e-01, -2.96875000e-01,\n",
       "       -6.88476562e-02,  2.10571289e-03,  6.07910156e-02, -5.22460938e-02,\n",
       "       -1.94335938e-01,  3.12500000e-01,  1.37695312e-01, -1.46484375e-01,\n",
       "        4.72656250e-01, -2.94921875e-01, -2.96875000e-01, -5.15747070e-03,\n",
       "       -9.96093750e-02,  3.37890625e-01, -8.83789062e-02, -5.20019531e-02,\n",
       "        5.02929688e-02,  2.01225281e-04,  1.06933594e-01, -2.25585938e-01,\n",
       "        1.10839844e-01, -1.05468750e-01, -9.27734375e-02,  1.59179688e-01,\n",
       "       -1.22558594e-01, -1.55273438e-01,  1.28906250e-01,  3.54003906e-02,\n",
       "       -4.04296875e-01,  2.22167969e-02,  1.66015625e-01, -5.46875000e-02,\n",
       "        1.08032227e-02,  8.74023438e-02, -1.81884766e-02,  1.53320312e-01,\n",
       "       -1.32812500e-01, -2.19726562e-02,  3.14453125e-01, -2.71484375e-01,\n",
       "        1.63085938e-01,  3.16406250e-01, -2.19726562e-01, -1.45507812e-01,\n",
       "        2.91748047e-02, -1.91406250e-01, -4.08203125e-01, -1.64062500e-01,\n",
       "        4.27734375e-01,  1.18652344e-01,  1.50390625e-01,  6.12792969e-02,\n",
       "       -1.73339844e-02,  1.55273438e-01, -1.28906250e-01, -5.18798828e-03,\n",
       "        5.42968750e-01,  1.63085938e-01,  3.63281250e-01,  1.36718750e-01,\n",
       "        7.47070312e-02, -3.24218750e-01, -7.27539062e-02, -3.08593750e-01,\n",
       "        1.62353516e-02,  3.37890625e-01, -3.53515625e-01,  4.08203125e-01,\n",
       "        2.92968750e-01, -3.06640625e-01, -1.59912109e-02, -8.88671875e-02,\n",
       "       -1.02539062e-01,  3.16406250e-01, -1.88476562e-01, -2.17773438e-01,\n",
       "        2.41699219e-02, -7.12890625e-02,  2.71484375e-01, -1.41601562e-01,\n",
       "       -2.80761719e-02, -8.69140625e-02,  3.90625000e-01,  1.04492188e-01,\n",
       "       -1.70898438e-01,  5.39550781e-02,  3.01513672e-02, -2.69531250e-01,\n",
       "        1.66992188e-01, -3.07617188e-02,  1.34765625e-01,  1.74804688e-01,\n",
       "        3.10546875e-01, -3.54003906e-03,  5.85937500e-01, -3.08593750e-01,\n",
       "       -1.62109375e-01,  2.11914062e-01,  1.45507812e-01,  1.96533203e-02,\n",
       "       -9.57031250e-02, -2.59765625e-01, -9.03320312e-02,  1.79687500e-01,\n",
       "        1.10839844e-01,  1.10839844e-01, -3.43750000e-01,  3.93066406e-02,\n",
       "       -2.50000000e-01, -2.89306641e-02, -5.68847656e-02,  3.22265625e-01,\n",
       "        1.92382812e-01,  1.89453125e-01, -2.40234375e-01,  5.29785156e-02,\n",
       "        3.80859375e-01,  1.68945312e-01,  1.00097656e-01, -2.57568359e-02,\n",
       "        1.15966797e-02, -4.47265625e-01, -8.97216797e-03, -3.29589844e-02,\n",
       "       -1.66015625e-01, -7.51953125e-02, -2.92968750e-01,  1.89453125e-01,\n",
       "       -1.69921875e-01,  0.00000000e+00,  4.76780129e-01, -1.15616491e+00,\n",
       "       -5.53112532e-01,  8.96619557e-01, -1.64547290e+00,  1.14850425e+00,\n",
       "       -6.80314012e-01, -6.26502129e-01, -4.20046710e-01,  4.79366147e-01,\n",
       "       -5.47006004e-01,  5.17227736e-01, -2.09539502e-01, -3.43615166e-01,\n",
       "       -4.34455729e-01,  8.01645655e-01, -6.45464060e-01,  2.85012067e-01,\n",
       "        5.86380491e-01,  6.87543678e-01,  1.44328070e-01,  5.96654810e-01,\n",
       "        4.12939676e-01, -7.80454737e-01, -6.18548309e-01, -1.60697899e-03,\n",
       "       -3.81612930e-01,  2.10756806e+00, -9.38996638e-01, -3.01210937e-02,\n",
       "       -1.45196310e+00, -3.11552891e-01,  3.25879289e-01,  3.54157178e-02,\n",
       "        2.98155559e-01, -4.61008761e-01, -9.14895638e-01,  3.98462991e-01,\n",
       "        6.49585930e-01, -2.28620288e-01,  1.62764828e+00,  1.08281395e+00,\n",
       "        1.88502779e-01, -2.64925851e-01,  9.37814271e-01, -5.11079741e-01,\n",
       "        3.27320086e-01,  2.44489271e-01, -3.54469172e-01, -4.14558325e-01,\n",
       "        2.10235435e-01,  5.35704843e-02, -6.96246540e-02,  4.00350316e-02,\n",
       "        2.06631932e-02,  5.85963331e-02, -1.13339384e-02, -2.27894772e-03,\n",
       "       -4.11443343e-02, -5.24203627e-02,  6.92205619e-02, -1.88347539e-02,\n",
       "        2.46645959e-02,  6.36709549e-02, -1.41948897e-02, -6.70537157e-02,\n",
       "       -4.31635230e-02,  6.35319903e-03, -4.48720506e-02,  6.47730967e-02,\n",
       "       -4.13129535e-02, -6.09232424e-02, -8.01604977e-02,  1.61097441e-02,\n",
       "        5.47935669e-02, -8.49431111e-03, -5.22356396e-02, -4.00815851e-02,\n",
       "        3.30676115e-02, -3.47425330e-02, -1.03204992e-01,  4.22498150e-04,\n",
       "        5.44789239e-02,  2.29694175e-02, -3.19508200e-02, -5.17621471e-02,\n",
       "        2.14661046e-02,  4.04531890e-02,  3.68953595e-02,  1.16173847e-02,\n",
       "       -1.72973280e-03,  3.09149453e-02,  4.44551145e-02, -1.18959454e-01,\n",
       "        1.29016562e-02, -3.49803564e-02, -3.45255237e-02, -2.23084269e-02,\n",
       "        1.31563313e-01,  5.11538483e-02])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['dam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5177"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx['guitar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx = {t: i for i, t in enumerate(tag)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_idx):\n",
    "    \n",
    "    idxs = [to_idx[w] for w in seq]\n",
    "    idxs = np.array(idxs)\n",
    "    output_idxs = torch.from_numpy(idxs)\n",
    "    output_idxs = output_idxs.type(torch.FloatTensor).cuda()\n",
    "    \n",
    "    return output_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        ''' Initialize the layers of this model.'''\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #LAYER1 : EMBEDDING LAYER\n",
    "        # embedding layer that turns words into a vector of a specified size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        #LAYER2 : LSTM\n",
    "        # the LSTM takes embedded word vectors (of a specified size) as inputs and outputs hidden states of size hidden_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "\n",
    "        #LAYER3 : DENSE\n",
    "        # the linear layer that maps the hidden state output dimension to the number of tags we want as output, tagset_size (in this case this is 3 tags)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
    "        \n",
    "        # initialize the hidden state (see code below)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        \n",
    "    def init_hidden(self):\n",
    "\n",
    "        # The axes dimensions are (n_layers, batch_size, hidden_dim)\n",
    "        return(torch.randn(2, 1, self.hidden_dim).cuda(),\n",
    "            torch.randn(2, 1, self.hidden_dim).cuda())\n",
    "        \n",
    "        #return (torch.zeros(2, 1, self.hidden_dim).cuda(),\n",
    "        #       torch.zeros(2, 1, self.hidden_dim).cuda())\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        embeds = sentence\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm((embeds.view(len(sentence), 1, -1)), self.hidden)\n",
    "                \n",
    "        # get the scores for the most likely tag for a word\n",
    "        tag_scores = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(3)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8a8ebe7cf0>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embedding dimension defines the size of our word vectors\n",
    "# for our simple vocabulary and training set, we will keep these small\n",
    "EMBEDDING_DIM = 402\n",
    "HIDDEN_DIM = 120\n",
    "\n",
    "# instantiate our model\n",
    "model1 = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), len(tag2idx))\n",
    "model1.cuda()\n",
    "\n",
    "# define our loss and optimizer\n",
    "loss_function =  nn.CrossEntropyLoss()  #nn.NLLLoss()   \n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.1)       ##SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [i, used, to, get, terrible, headaches, from, ...\n",
       "1      [peters, s, pain, and, symptoms, were, caused,...\n",
       "2      [in, the, years, since, the, adm, scandal, of,...\n",
       "3      [a, first, revolution, was, triggered, by, the...\n",
       "4      [when, they, took, the, floor, against, a, tea...\n",
       "                             ...                        \n",
       "797    [using, solar, electricity, instead, of, conve...\n",
       "798    [fatigue, corrosion, and, stress, corrosion, a...\n",
       "799    [the, electromagnetic, em, radiation, from, th...\n",
       "800    [it, gets, a, little, bit, chicken, first, or,...\n",
       "801    [the, microphone, converts, sound, into, an, e...\n",
       "Name: token, Length: 802, dtype: object"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [many, adults, retain, scars, from, acne, brea...\n",
       "1      [we, estimate, a, wind, speed, associated, wit...\n",
       "2      [outbreaks, caused, by, the, oral, vaccine, s,...\n",
       "3      [production, and, investigation, of, such, a, ...\n",
       "4      [the, drugs, he, sold, had, caused, the, overd...\n",
       "                             ...                        \n",
       "196    [the, real, possibility, of, total, engulfment...\n",
       "197    [we, find, evidence, that, ernst, suffered, a,...\n",
       "198    [the, influx, caused, a, further, drain, on, t...\n",
       "199    [ngu, nongonococcal, urethritis, is, an, infec...\n",
       "200    [eye, discomfort, from, this, staring, effect,...\n",
       "Name: token, Length: 201, dtype: object"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_data = []\n",
    "for i in range(len(train_x)):\n",
    "    sen = train_x[i]\n",
    "    tag = train_y[i]\n",
    "    sen_t = prepare_sequence(sen, word2idx)\n",
    "    tag_t = prepare_sequence(tag, tag2idx)\n",
    "    training_input_data.append((sen_t, tag_t))\n",
    "    \n",
    "    \n",
    "testing_input_data = []\n",
    "for i in range(len(test_x)):\n",
    "    sen = test_x[i]\n",
    "    tag = test_y[i]\n",
    "    sen_t = prepare_sequence(sen, word2idx)\n",
    "    tag_t = prepare_sequence(tag, tag2idx)\n",
    "    testing_input_data.append((sen_t, tag_t))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_input_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.37979\n",
      "--- 4.5094990730285645 seconds ---\n",
      "Epoch: 2, loss: 0.29686\n",
      "--- 8.843169927597046 seconds ---\n",
      "Epoch: 3, loss: 0.26581\n",
      "--- 13.295043468475342 seconds ---\n",
      "Epoch: 4, loss: 0.24212\n",
      "--- 17.726362705230713 seconds ---\n",
      "Epoch: 5, loss: 0.22042\n",
      "--- 22.18460488319397 seconds ---\n",
      "Epoch: 6, loss: 0.20351\n",
      "--- 26.614367246627808 seconds ---\n",
      "Epoch: 7, loss: 0.18584\n",
      "--- 31.06912660598755 seconds ---\n",
      "Epoch: 8, loss: 0.17068\n",
      "--- 35.50715899467468 seconds ---\n",
      "Epoch: 9, loss: 0.15479\n",
      "--- 39.9329469203949 seconds ---\n",
      "Epoch: 10, loss: 0.14721\n",
      "--- 44.350550413131714 seconds ---\n",
      "Epoch: 11, loss: 0.13186\n",
      "--- 48.772984743118286 seconds ---\n",
      "Epoch: 12, loss: 0.12377\n",
      "--- 53.227378606796265 seconds ---\n",
      "Epoch: 13, loss: 0.10995\n",
      "--- 57.65360951423645 seconds ---\n",
      "Epoch: 14, loss: 0.10053\n",
      "--- 62.07853031158447 seconds ---\n",
      "Epoch: 15, loss: 0.09381\n",
      "--- 66.5236988067627 seconds ---\n",
      "Total time taken : \n",
      "--- 66.52557945251465 seconds ---\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "score_save = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    count=0\n",
    "    \n",
    "    for sentence, tags in training_input_data:\n",
    "        if len(sentence)>0:\n",
    "            count+=1\n",
    "            \n",
    "            model1.zero_grad()\n",
    "\n",
    "            # zero the hidden state of the LSTM, this detaches it from its history\n",
    "            model1.hidden = model1.init_hidden()\n",
    "\n",
    "           \n",
    "            tags = tags.type(torch.LongTensor)  #.cuda()\n",
    "            \n",
    "            tag_scores = model1(sentence)\n",
    "            \n",
    "            # Loss\n",
    "            tag_scores = tag_scores.type(torch.FloatTensor)  #.cuda()\n",
    "            #targets = targets.type(torch.LongTensor).cuda()\n",
    "            if epoch==n_epochs-1:\n",
    "                score_save.append(tag_scores.tolist())\n",
    "            \n",
    "            loss = loss_function(tag_scores, tags)\n",
    "            #print(loss)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            # update the model parameters with optimizer.step()\n",
    "            optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, epoch_loss/len(train_x)))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"Total time taken : \")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for training data\n",
    "\n",
    "pred_tag = []\n",
    "actual_tag = []\n",
    "for sen, tag in training_input_data:\n",
    "    tag_scores = model1(sen)\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "    pred = predicted_tags.cpu().tolist()\n",
    "    pred = [idx2tag[idx] for idx in pred]\n",
    "    pred_tag.append(pred)\n",
    "    tag = tag.cpu().tolist()\n",
    "    act = [idx2tag[idx] for idx in tag]\n",
    "    actual_tag.append(act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_f = [item for sublist in pred_tag for item in sublist]\n",
    "actual_tag_f = [item for sublist in actual_tag for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.61      0.74       890\n",
      "           C       0.93      0.72      0.81       887\n",
      "           E       0.96      1.00      0.98     13185\n",
      "\n",
      "    accuracy                           0.96     14962\n",
      "   macro avg       0.94      0.77      0.84     14962\n",
      "weighted avg       0.96      0.96      0.95     14962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['O', 'C', 'E']\n",
    "\n",
    "print(classification_report(actual_tag_f, pred_tag_f,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for testing data\n",
    "\n",
    "pred_tag = []\n",
    "actual_tag = []\n",
    "for sen, tag in testing_input_data:\n",
    "    tag_scores = model1(sen)\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "    pred = predicted_tags.cpu().tolist()\n",
    "    pred = [idx2tag[idx] for idx in pred]\n",
    "    pred_tag.append(pred)\n",
    "    tag = tag.cpu().tolist()\n",
    "    act = [idx2tag[idx] for idx in tag]\n",
    "    actual_tag.append(act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_f = [item for sublist in pred_tag for item in sublist]\n",
    "actual_tag_f = [item for sublist in actual_tag for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.59      0.33      0.43       224\n",
      "           C       0.69      0.50      0.58       217\n",
      "           E       0.94      0.98      0.96      3516\n",
      "\n",
      "    accuracy                           0.91      3957\n",
      "   macro avg       0.74      0.60      0.65      3957\n",
      "weighted avg       0.90      0.91      0.91      3957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['O', 'C', 'E']\n",
    "\n",
    "print(classification_report(actual_tag_f, pred_tag_f,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_x(sen):\n",
    "    sen = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', sen)\n",
    "    sen = sen.replace('.', ' ')\n",
    "    sen = sen.lower()\n",
    "    sen = sen.split()\n",
    "    return sen\n",
    "\n",
    "def clean_y(rel):\n",
    "    cause = rel[0]\n",
    "    cause = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', cause)\n",
    "    cause = cause.lower().split()\n",
    "    effect = rel[1]\n",
    "    effect = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', effect)\n",
    "    effect = effect.lower().split()\n",
    "\n",
    "    return ((cause, effect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST WITH ANY INPUT SENTENCE\n",
    "\n",
    "\n",
    "def test_with_sen(input_sen):\n",
    "    input_sen = clean_x(input_sen)\n",
    "    \n",
    "    inputs = prepare_sequence(input_sen, word2idx)\n",
    "\n",
    "    tag_scores = model1(inputs)\n",
    "\n",
    "\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "\n",
    "    print(\"Input sentence: \", input_sen)\n",
    "    for i in range(0,len(input_sen)):\n",
    "        t = ''\n",
    "        if predicted_tags[i].item()==0:\n",
    "            t = 'Other'\n",
    "        elif predicted_tags[i].item()==1:\n",
    "            t = 'Cause'\n",
    "        elif predicted_tags[i].item()==2:\n",
    "            t = 'Effect'\n",
    "        #elif predicted_tags[i].item==3:\n",
    "        #    t = 'B-Effect'\n",
    "        #else:\n",
    "        #    t = 'I-Effect'\n",
    "        print(predicted_tags[i].item())\n",
    "        print(input_sen[i] , ': ', t )\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  ['smoking', 'causes', 'cancer']\n",
      "1\n",
      "smoking :  Cause\n",
      "0\n",
      "causes :  Other\n",
      "0\n",
      "cancer :  Other\n"
     ]
    }
   ],
   "source": [
    "test_sen = 'Smoking causes cancer'\n",
    "test_with_sen(test_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are many types and causes of headaches from tension headaches due to stress to migraines triggered by certain foods\n",
      "Input sentence:  ['there', 'are', 'many', 'types', 'and', 'causes', 'of', 'headaches', 'from', 'tension', 'headaches', 'due', 'to', 'stress', 'to', 'migraines', 'triggered', 'by', 'certain', 'foods']\n",
      "0\n",
      "there :  Other\n",
      "0\n",
      "are :  Other\n",
      "0\n",
      "many :  Other\n",
      "0\n",
      "types :  Other\n",
      "0\n",
      "and :  Other\n",
      "0\n",
      "causes :  Other\n",
      "0\n",
      "of :  Other\n",
      "2\n",
      "headaches :  Effect\n",
      "0\n",
      "from :  Other\n",
      "0\n",
      "tension :  Other\n",
      "2\n",
      "headaches :  Effect\n",
      "0\n",
      "due :  Other\n",
      "0\n",
      "to :  Other\n",
      "1\n",
      "stress :  Cause\n",
      "0\n",
      "to :  Other\n",
      "2\n",
      "migraines :  Effect\n",
      "0\n",
      "triggered :  Other\n",
      "0\n",
      "by :  Other\n",
      "0\n",
      "certain :  Other\n",
      "1\n",
      "foods :  Cause\n"
     ]
    }
   ],
   "source": [
    "a = ' '.join(test_x[46])\n",
    "\n",
    "print(a)\n",
    "test_with_sen(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
