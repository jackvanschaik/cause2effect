{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train.pkl\")\n",
    "test = pd.read_pickle(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['token']\n",
    "train_y = train['label']\n",
    "train_id = train['sen_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test['token']\n",
    "test_y = test['label']\n",
    "test_id = test['sen_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([item for sublist in train_x for item in sublist] + [item for sublist in test_x for item in sublist])\n",
    "tag = ['O', 'C', 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_300 = np.array([0] * 300)\n",
    "zero_301 = np.concatenate((np.array([1]), zero_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "\n",
    "not_present = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vocab:\n",
    "    try:\n",
    "        vec = model[i]\n",
    "        vec1 = np.concatenate((np.array([0]), vec))\n",
    "        word2idx[i]= vec1\n",
    "        \n",
    "    except:\n",
    "        word2idx[i]= zero_301\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5177"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx['guitar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tag2idx = {t: i for i, t in enumerate(tag)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_idx):\n",
    "    \n",
    "    idxs = [to_idx[w] for w in seq]\n",
    "    idxs = np.array(idxs)\n",
    "    output_idxs = torch.from_numpy(idxs)\n",
    "    output_idxs = output_idxs.type(torch.FloatTensor).cuda()\n",
    "    \n",
    "    return output_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        ''' Initialize the layers of this model.'''\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #LAYER1 : EMBEDDING LAYER\n",
    "        # embedding layer that turns words into a vector of a specified size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        #LAYER2 : LSTM\n",
    "        # the LSTM takes embedded word vectors (of a specified size) as inputs and outputs hidden states of size hidden_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "\n",
    "        #LAYER3 : DENSE\n",
    "        # the linear layer that maps the hidden state output dimension to the number of tags we want as output, tagset_size (in this case this is 3 tags)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
    "        \n",
    "        # initialize the hidden state (see code below)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        \n",
    "    def init_hidden(self):\n",
    "\n",
    "        # The axes dimensions are (n_layers, batch_size, hidden_dim)\n",
    "        \n",
    "        #return(torch.randn(2, 1, self.hidden_dim).cuda(),\n",
    "        #    torch.randn(2, 1, self.hidden_dim).cuda())\n",
    "    \n",
    "        return (torch.zeros(2, 1, self.hidden_dim).cuda(),\n",
    "                torch.zeros(2, 1, self.hidden_dim).cuda())\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "       \n",
    "        embeds = sentence\n",
    "        #print(embeds.shape)\n",
    "        \n",
    "        #print((embeds.view(len(sentence), 1, -1)).shape)\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm((embeds.view(len(sentence), 1, -1)), self.hidden)\n",
    "        #print(lstm_out.shape)\n",
    "        \n",
    "        # get the scores for the most likely tag for a word\n",
    "        tag_scores = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(3)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f814020bbf0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embedding dimension defines the size of our word vectors\n",
    "# for our simple vocabulary and training set, we will keep these small\n",
    "EMBEDDING_DIM = 301\n",
    "HIDDEN_DIM = 120\n",
    "\n",
    "# instantiate our model\n",
    "model1 = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), len(tag2idx))\n",
    "model1.cuda()\n",
    "\n",
    "# define our loss and optimizer\n",
    "loss_function =  nn.CrossEntropyLoss()  #nn.NLLLoss()   \n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.1)       ##SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [i, used, to, get, terrible, headaches, from, ...\n",
       "1      [peters, s, pain, and, symptoms, were, caused,...\n",
       "2      [in, the, years, since, the, adm, scandal, of,...\n",
       "3      [a, first, revolution, was, triggered, by, the...\n",
       "4      [when, they, took, the, floor, against, a, tea...\n",
       "                             ...                        \n",
       "797    [using, solar, electricity, instead, of, conve...\n",
       "798    [fatigue, corrosion, and, stress, corrosion, a...\n",
       "799    [the, electromagnetic, em, radiation, from, th...\n",
       "800    [it, gets, a, little, bit, chicken, first, or,...\n",
       "801    [the, microphone, converts, sound, into, an, e...\n",
       "Name: token, Length: 802, dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [many, adults, retain, scars, from, acne, brea...\n",
       "1      [we, estimate, a, wind, speed, associated, wit...\n",
       "2      [outbreaks, caused, by, the, oral, vaccine, s,...\n",
       "3      [production, and, investigation, of, such, a, ...\n",
       "4      [the, drugs, he, sold, had, caused, the, overd...\n",
       "                             ...                        \n",
       "196    [the, real, possibility, of, total, engulfment...\n",
       "197    [we, find, evidence, that, ernst, suffered, a,...\n",
       "198    [the, influx, caused, a, further, drain, on, t...\n",
       "199    [ngu, nongonococcal, urethritis, is, an, infec...\n",
       "200    [eye, discomfort, from, this, staring, effect,...\n",
       "Name: token, Length: 201, dtype: object"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_data = []\n",
    "for i in range(len(train_x)):\n",
    "    sen = train_x[i]\n",
    "    tag = train_y[i]\n",
    "    sen_t = prepare_sequence(sen, word2idx)\n",
    "    tag_t = prepare_sequence(tag, tag2idx)\n",
    "    training_input_data.append((sen_t, tag_t))\n",
    "    \n",
    "    \n",
    "testing_input_data = []\n",
    "for i in range(len(test_x)):\n",
    "    sen = test_x[i]\n",
    "    tag = test_y[i]\n",
    "    sen_t = prepare_sequence(sen, word2idx)\n",
    "    tag_t = prepare_sequence(tag, tag2idx)\n",
    "    testing_input_data.append((sen_t, tag_t))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_input_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.43536\n",
      "--- 4.966158151626587 seconds ---\n",
      "Epoch: 2, loss: 0.31675\n",
      "--- 10.054753303527832 seconds ---\n",
      "Epoch: 3, loss: 0.27250\n",
      "--- 15.240069389343262 seconds ---\n",
      "Epoch: 4, loss: 0.24484\n",
      "--- 20.281968355178833 seconds ---\n",
      "Epoch: 5, loss: 0.22212\n",
      "--- 25.012757539749146 seconds ---\n",
      "Epoch: 6, loss: 0.20271\n",
      "--- 29.83329129219055 seconds ---\n",
      "Epoch: 7, loss: 0.18662\n",
      "--- 34.940752267837524 seconds ---\n",
      "Epoch: 8, loss: 0.17309\n",
      "--- 40.00309920310974 seconds ---\n",
      "Epoch: 9, loss: 0.16132\n",
      "--- 44.855435848236084 seconds ---\n",
      "Epoch: 10, loss: 0.15103\n",
      "--- 49.7520067691803 seconds ---\n",
      "Epoch: 11, loss: 0.14170\n",
      "--- 54.78516912460327 seconds ---\n",
      "Epoch: 12, loss: 0.13287\n",
      "--- 59.84591364860535 seconds ---\n",
      "Epoch: 13, loss: 0.12430\n",
      "--- 64.88073539733887 seconds ---\n",
      "Epoch: 14, loss: 0.11588\n",
      "--- 69.62064933776855 seconds ---\n",
      "Epoch: 15, loss: 0.10745\n",
      "--- 74.61324453353882 seconds ---\n",
      "Total time taken : \n",
      "--- 74.61415505409241 seconds ---\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "score_save = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    count=0\n",
    "    \n",
    "    for sentence, tags in training_input_data:\n",
    "        if len(sentence)>0:\n",
    "            count+=1\n",
    "            \n",
    "            model1.zero_grad()\n",
    "\n",
    "            # zero the hidden state of the LSTM, this detaches it from its history\n",
    "            model1.hidden = model1.init_hidden()\n",
    "\n",
    "   \n",
    "            # forward \n",
    "           \n",
    "            tags = tags.type(torch.LongTensor).cuda()\n",
    "            \n",
    "            tag_scores = model1(sentence)\n",
    "            \n",
    "            # Loss\n",
    "            tag_scores = tag_scores.type(torch.FloatTensor).cuda()\n",
    "            \n",
    "            if epoch==n_epochs-1:\n",
    "                score_save.append(tag_scores.tolist())\n",
    "            \n",
    "            loss = loss_function(tag_scores, tags)\n",
    "            #print(loss)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            # update the model parameters with optimizer.step()\n",
    "            optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, epoch_loss/len(train_x)))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"Total time taken : \")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for training data\n",
    "\n",
    "pred_tag = []\n",
    "actual_tag = []\n",
    "for sen, tag in training_input_data:\n",
    "    tag_scores = model1(sen)\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "    pred = predicted_tags.cpu().tolist()\n",
    "    pred = [idx2tag[idx] for idx in pred]\n",
    "    pred_tag.append(pred)\n",
    "    tag = tag.cpu().tolist()\n",
    "    act = [idx2tag[idx] for idx in tag]\n",
    "    actual_tag.append(act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_f = [item for sublist in pred_tag for item in sublist]\n",
    "actual_tag_f = [item for sublist in actual_tag for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.88      0.52      0.65       890\n",
      "           C       0.86      0.67      0.75       887\n",
      "           E       0.95      0.99      0.97     13185\n",
      "\n",
      "    accuracy                           0.94     14962\n",
      "   macro avg       0.90      0.73      0.79     14962\n",
      "weighted avg       0.94      0.94      0.94     14962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['O', 'C', 'E']\n",
    "\n",
    "print(classification_report(actual_tag_f, pred_tag_f,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for testing data\n",
    "\n",
    "pred_tag = []\n",
    "actual_tag = []\n",
    "for sen, tag in testing_input_data:\n",
    "    tag_scores = model1(sen)\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "    pred = predicted_tags.cpu().tolist()\n",
    "    pred = [idx2tag[idx] for idx in pred]\n",
    "    pred_tag.append(pred)\n",
    "    tag = tag.cpu().tolist()\n",
    "    act = [idx2tag[idx] for idx in tag]\n",
    "    actual_tag.append(act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_f = [item for sublist in pred_tag for item in sublist]\n",
    "actual_tag_f = [item for sublist in actual_tag for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.63      0.38      0.47       224\n",
      "           C       0.70      0.62      0.66       217\n",
      "           E       0.94      0.98      0.96      3516\n",
      "\n",
      "    accuracy                           0.92      3957\n",
      "   macro avg       0.76      0.66      0.70      3957\n",
      "weighted avg       0.91      0.92      0.92      3957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['O', 'C', 'E']\n",
    "\n",
    "print(classification_report(actual_tag_f, pred_tag_f,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_x(sen):\n",
    "    sen = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', sen)\n",
    "    sen = sen.replace('.', ' ')\n",
    "    sen = sen.lower()\n",
    "    sen = sen.split()\n",
    "    return sen\n",
    "\n",
    "def clean_y(rel):\n",
    "    cause = rel[0]\n",
    "    cause = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', cause)\n",
    "    cause = cause.lower().split()\n",
    "    effect = rel[1]\n",
    "    effect = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', effect)\n",
    "    effect = effect.lower().split()\n",
    "\n",
    "    return ((cause, effect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST WITH ANY INPUT SENTENCE\n",
    "\n",
    "\n",
    "def test_with_sen(input_sen):\n",
    "    #input_sen = 'Smoking causes cancer'\n",
    "    #input_sen = 'For example , the book also described how to distinguish between a drowning (water in the lungs) and strangulation (broken neck cartilage), along with other evidence from examining corpses on determining if a death was caused by murder, suicide or an accident.'\n",
    "    input_sen = clean_x(input_sen)\n",
    "    #input_sen = input_sen.lower().replace(\".\", \"\")\n",
    "\n",
    "    inputs = prepare_sequence(input_sen, word2idx)\n",
    "\n",
    "    tag_scores = model1(inputs)\n",
    "\n",
    "\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "\n",
    "    print(\"Input sentence: \", input_sen)\n",
    "    for i in range(0,len(input_sen)):\n",
    "        t = ''\n",
    "        if predicted_tags[i].item()==0:\n",
    "            t = 'Other'\n",
    "        elif predicted_tags[i].item()==1:\n",
    "            t = 'Cause'\n",
    "        elif predicted_tags[i].item()==2:\n",
    "            t = 'Effect'\n",
    "        #elif predicted_tags[i].item==3:\n",
    "        #    t = 'B-Effect'\n",
    "        #else:\n",
    "        #    t = 'I-Effect'\n",
    "        print(predicted_tags[i].item())\n",
    "        print(input_sen[i] , ': ', t )\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sen = 'Smoking causes cancer'\n",
    "test_with_sen(test_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ' '.join(test_x[46])\n",
    "\n",
    "print(a)\n",
    "test_with_sen(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
