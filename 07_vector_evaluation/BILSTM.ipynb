{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train.pkl\")\n",
    "test = pd.read_pickle(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['token']\n",
    "train_y = train['label']\n",
    "train_id = train['sen_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test['token']\n",
    "test_y = test['label']\n",
    "test_id = test['sen_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([item for sublist in train_x for item in sublist] + [item for sublist in test_x for item in sublist])\n",
    "tag = ['O', 'C', 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "tag2idx = {t: i for i, t in enumerate(tag)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_idx):\n",
    "    \n",
    "    idxs = [to_idx[w] for w in seq]\n",
    "    idxs = np.array(idxs)\n",
    "    output_idxs = torch.from_numpy(idxs)\n",
    "    output_idxs = output_idxs.type(torch.LongTensor).cuda()\n",
    "    \n",
    "    return output_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        ''' Initialize the layers of this model.'''\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #LAYER1 : EMBEDDING LAYER\n",
    "        # embedding layer that turns words into a vector of a specified size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        #LAYER2 : LSTM\n",
    "        # the LSTM takes embedded word vectors (of a specified size) as inputs and outputs hidden states of size hidden_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "\n",
    "        #LAYER3 : DENSE\n",
    "        # the linear layer that maps the hidden state output dimension to the number of tags we want as output, tagset_size (in this case this is 3 tags)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
    "        \n",
    "        # initialize the hidden state (see code below)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        \n",
    "    def init_hidden(self):\n",
    "\n",
    "        # The axes dimensions are (n_layers, batch_size, hidden_dim)\n",
    "        return(torch.randn(2, 1, self.hidden_dim).cuda(),\n",
    "            torch.randn(2, 1, self.hidden_dim).cuda())\n",
    "        \n",
    "        #return (torch.zeros(2, 1, self.hidden_dim).cuda(),\n",
    "        #        torch.zeros(2, 1, self.hidden_dim).cuda())\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        # LAYER1\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        #print(embeds.shape)\n",
    "        #print((embeds.view(len(sentence), 1, -1)).shape)\n",
    "        lstm_out, self.hidden = self.lstm(embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        #print(lstm_out.shape)\n",
    "        \n",
    "        # get the scores for the most likely tag for a word\n",
    "        tag_scores = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        #tag_scores = F.softmax(tag_outputs)\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(3)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8a38129bf0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embedding dimension defines the size of our word vectors\n",
    "# for our simple vocabulary and training set, we will keep these small\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 120\n",
    "\n",
    "# instantiate our model\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), len(tag2idx))\n",
    "model.cuda()\n",
    "\n",
    "# define our loss and optimizer\n",
    "loss_function =  nn.CrossEntropyLoss()  #nn.NLLLoss()   \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)       ##SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [i, used, to, get, terrible, headaches, from, ...\n",
       "1      [peters, s, pain, and, symptoms, were, caused,...\n",
       "2      [in, the, years, since, the, adm, scandal, of,...\n",
       "3      [a, first, revolution, was, triggered, by, the...\n",
       "4      [when, they, took, the, floor, against, a, tea...\n",
       "                             ...                        \n",
       "797    [using, solar, electricity, instead, of, conve...\n",
       "798    [fatigue, corrosion, and, stress, corrosion, a...\n",
       "799    [the, electromagnetic, em, radiation, from, th...\n",
       "800    [it, gets, a, little, bit, chicken, first, or,...\n",
       "801    [the, microphone, converts, sound, into, an, e...\n",
       "Name: token, Length: 802, dtype: object"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [many, adults, retain, scars, from, acne, brea...\n",
       "1      [we, estimate, a, wind, speed, associated, wit...\n",
       "2      [outbreaks, caused, by, the, oral, vaccine, s,...\n",
       "3      [production, and, investigation, of, such, a, ...\n",
       "4      [the, drugs, he, sold, had, caused, the, overd...\n",
       "                             ...                        \n",
       "196    [the, real, possibility, of, total, engulfment...\n",
       "197    [we, find, evidence, that, ernst, suffered, a,...\n",
       "198    [the, influx, caused, a, further, drain, on, t...\n",
       "199    [ngu, nongonococcal, urethritis, is, an, infec...\n",
       "200    [eye, discomfort, from, this, staring, effect,...\n",
       "Name: token, Length: 201, dtype: object"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_data = []\n",
    "for i in range(len(train_x)):\n",
    "    sen = train_x[i]\n",
    "    tag = train_y[i]\n",
    "    sen_t = prepare_sequence(sen, word2idx)\n",
    "    tag_t = prepare_sequence(tag, tag2idx)\n",
    "    training_input_data.append((sen_t, tag_t))\n",
    "    \n",
    "    \n",
    "testing_input_data = []\n",
    "for i in range(len(test_x)):\n",
    "    sen = test_x[i]\n",
    "    tag = test_y[i]\n",
    "    sen_t = prepare_sequence(sen, word2idx)\n",
    "    tag_t = prepare_sequence(tag, tag2idx)\n",
    "    testing_input_data.append((sen_t, tag_t))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_input_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.40360\n",
      "--- 5.032696008682251 seconds ---\n",
      "Epoch: 2, loss: 0.26261\n",
      "--- 10.003289937973022 seconds ---\n",
      "Epoch: 3, loss: 0.17546\n",
      "--- 14.981546878814697 seconds ---\n",
      "Epoch: 4, loss: 0.11212\n",
      "--- 19.966896057128906 seconds ---\n",
      "Epoch: 5, loss: 0.07093\n",
      "--- 24.939717531204224 seconds ---\n",
      "Epoch: 6, loss: 0.04564\n",
      "--- 29.920954942703247 seconds ---\n",
      "Epoch: 7, loss: 0.03043\n",
      "--- 34.88499045372009 seconds ---\n",
      "Epoch: 8, loss: 0.02150\n",
      "--- 39.959354639053345 seconds ---\n",
      "Epoch: 9, loss: 0.01614\n",
      "--- 44.953657388687134 seconds ---\n",
      "Epoch: 10, loss: 0.01284\n",
      "--- 49.927570819854736 seconds ---\n",
      "Epoch: 11, loss: 0.01070\n",
      "--- 54.90127110481262 seconds ---\n",
      "Epoch: 12, loss: 0.00924\n",
      "--- 59.79249954223633 seconds ---\n",
      "Epoch: 13, loss: 0.00818\n",
      "--- 64.77915263175964 seconds ---\n",
      "Epoch: 14, loss: 0.00738\n",
      "--- 69.96769165992737 seconds ---\n",
      "Epoch: 15, loss: 0.00673\n",
      "--- 75.22159028053284 seconds ---\n",
      "Total time taken : \n",
      "--- 75.22228407859802 seconds ---\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "score_save = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    count=0\n",
    "    \n",
    "    for sentence, tags in training_input_data:\n",
    "        if len(sentence)>0:\n",
    "            count+=1\n",
    "            \n",
    "            model.zero_grad()\n",
    "\n",
    "            # zero the hidden state of the LSTM, this detaches it from its history\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            # forward \n",
    "           \n",
    "            tag_scores = model(sentence)\n",
    "            \n",
    "            # Loss\n",
    "            tag_scores = tag_scores.type(torch.DoubleTensor).cuda()\n",
    "            \n",
    "            if epoch==n_epochs-1:\n",
    "                score_save.append(tag_scores.tolist())\n",
    "            \n",
    "            loss = loss_function(tag_scores, tags)\n",
    "            #print(loss)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            # update the model parameters with optimizer.step()\n",
    "            optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, epoch_loss/len(train_x)))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"Total time taken : \")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for training data\n",
    "\n",
    "pred_tag = []\n",
    "actual_tag = []\n",
    "for sen, tag in training_input_data:\n",
    "    tag_scores = model(sen)\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "    pred = predicted_tags.cpu().tolist()\n",
    "    pred = [idx2tag[idx] for idx in pred]\n",
    "    pred_tag.append(pred)\n",
    "    tag = tag.cpu().tolist()\n",
    "    act = [idx2tag[idx] for idx in tag]\n",
    "    actual_tag.append(act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_f = [item for sublist in pred_tag for item in sublist]\n",
    "actual_tag_f = [item for sublist in actual_tag for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.98      0.95      0.96       890\n",
      "           C       0.99      0.97      0.98       887\n",
      "           E       0.99      1.00      1.00     13185\n",
      "\n",
      "    accuracy                           0.99     14962\n",
      "   macro avg       0.99      0.97      0.98     14962\n",
      "weighted avg       0.99      0.99      0.99     14962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['O', 'C', 'E']\n",
    "\n",
    "print(classification_report(actual_tag_f, pred_tag_f,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for testing data\n",
    "\n",
    "pred_tag = []\n",
    "actual_tag = []\n",
    "for sen, tag in testing_input_data:\n",
    "    tag_scores = model(sen)\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "    pred = predicted_tags.cpu().tolist()\n",
    "    pred = [idx2tag[idx] for idx in pred]\n",
    "    pred_tag.append(pred)\n",
    "    tag = tag.cpu().tolist()\n",
    "    act = [idx2tag[idx] for idx in tag]\n",
    "    actual_tag.append(act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_f = [item for sublist in pred_tag for item in sublist]\n",
    "actual_tag_f = [item for sublist in actual_tag for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.54      0.36      0.43       224\n",
      "           C       0.72      0.59      0.65       217\n",
      "           E       0.94      0.97      0.95      3516\n",
      "\n",
      "    accuracy                           0.91      3957\n",
      "   macro avg       0.73      0.64      0.68      3957\n",
      "weighted avg       0.91      0.91      0.91      3957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['O', 'C', 'E']\n",
    "\n",
    "print(classification_report(actual_tag_f, pred_tag_f,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_x(sen):\n",
    "    sen = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', sen)\n",
    "    sen = sen.replace('.', ' ')\n",
    "    sen = sen.lower()\n",
    "    sen = sen.split()\n",
    "    return sen\n",
    "\n",
    "def clean_y(rel):\n",
    "    cause = rel[0]\n",
    "    cause = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', cause)\n",
    "    cause = cause.lower().split()\n",
    "    effect = rel[1]\n",
    "    effect = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', effect)\n",
    "    effect = effect.lower().split()\n",
    "\n",
    "    return ((cause, effect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST WITH ANY INPUT SENTENCE\n",
    "\n",
    "\n",
    "def test_with_sen(input_sen):\n",
    "    #input_sen = 'Smoking causes cancer'\n",
    "    #input_sen = 'For example , the book also described how to distinguish between a drowning (water in the lungs) and strangulation (broken neck cartilage), along with other evidence from examining corpses on determining if a death was caused by murder, suicide or an accident.'\n",
    "    input_sen = clean_x(input_sen)\n",
    "    #input_sen = input_sen.lower().replace(\".\", \"\")\n",
    "\n",
    "    inputs = prepare_sequence(input_sen, word2idx)\n",
    "\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "\n",
    "    _, predicted_tags = torch.max(tag_scores, 1)\n",
    "\n",
    "    print(\"Input sentence: \", input_sen)\n",
    "    for i in range(0,len(input_sen)):\n",
    "        t = ''\n",
    "        if predicted_tags[i].item()==0:\n",
    "            t = 'Other'\n",
    "        elif predicted_tags[i].item()==1:\n",
    "            t = 'Cause'\n",
    "        elif predicted_tags[i].item()==2:\n",
    "            t = 'Effect'\n",
    "        #elif predicted_tags[i].item==3:\n",
    "        #    t = 'B-Effect'\n",
    "        #else:\n",
    "        #    t = 'I-Effect'\n",
    "        print(predicted_tags[i].item())\n",
    "        print(input_sen[i] , ': ', t )\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  ['smoking', 'causes', 'cancer']\n",
      "1\n",
      "smoking :  Cause\n",
      "0\n",
      "causes :  Other\n",
      "2\n",
      "cancer :  Effect\n"
     ]
    }
   ],
   "source": [
    "test_sen = 'Smoking causes cancer'\n",
    "test_with_sen(test_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are many types and causes of headaches from tension headaches due to stress to migraines triggered by certain foods\n",
      "Input sentence:  ['there', 'are', 'many', 'types', 'and', 'causes', 'of', 'headaches', 'from', 'tension', 'headaches', 'due', 'to', 'stress', 'to', 'migraines', 'triggered', 'by', 'certain', 'foods']\n",
      "0\n",
      "there :  Other\n",
      "0\n",
      "are :  Other\n",
      "0\n",
      "many :  Other\n",
      "0\n",
      "types :  Other\n",
      "0\n",
      "and :  Other\n",
      "0\n",
      "causes :  Other\n",
      "0\n",
      "of :  Other\n",
      "2\n",
      "headaches :  Effect\n",
      "0\n",
      "from :  Other\n",
      "1\n",
      "tension :  Cause\n",
      "2\n",
      "headaches :  Effect\n",
      "0\n",
      "due :  Other\n",
      "0\n",
      "to :  Other\n",
      "0\n",
      "stress :  Other\n",
      "0\n",
      "to :  Other\n",
      "2\n",
      "migraines :  Effect\n",
      "0\n",
      "triggered :  Other\n",
      "0\n",
      "by :  Other\n",
      "0\n",
      "certain :  Other\n",
      "0\n",
      "foods :  Other\n"
     ]
    }
   ],
   "source": [
    "a = ' '.join(test_x[46])\n",
    "\n",
    "print(a)\n",
    "test_with_sen(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
